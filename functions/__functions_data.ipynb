{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c37138-639f-40da-bd4c-d6895ae902cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smooth data\n",
    "\n",
    "def smoothed(x, n=300, k=3, y=None, return_type='df', datetime_index=False):\n",
    "    '''\n",
    "    Smooth data for plots\n",
    "    \n",
    "    Arguments:\n",
    "    x: pd.DataFrame, pd.Series\n",
    "    y: array-type\n",
    "    n: length of linespace\n",
    "    k: smoothing scale\n",
    "    return_type: \n",
    "        - if 'array' - return x_new, y_new\n",
    "        - if 'dict' - returns dict with {'x': x_new, 'y': y_new}\n",
    "\n",
    "    If x == pd.DataFrame functon returns pd.DataFrame anyway\n",
    "\n",
    "    Libraries:\n",
    "    from scipy.interpolate import make_interp_spline, BSpline\n",
    "    '''\n",
    "\n",
    "    if datetime_index:\n",
    "        start = x.index[0]\n",
    "        end = x.index[-1]\n",
    "        time_range = \\\n",
    "            pd.date_range(start=start, end=end, periods=n)\n",
    "        x = x.reset_index(drop=True)\n",
    "\n",
    "    if isinstance(x, pd.DataFrame):\n",
    "        var_name = x.columns[0] if x.columns[0] != 0 else 'variable'\n",
    "        x_index = x.index\n",
    "        x_new = np.linspace(x_index.min(), x_index.max(), n)\n",
    "        df = pd.DataFrame(index=x_new, columns=x.columns)\n",
    "        for col in x.columns:\n",
    "            y = x[col]\n",
    "            spl = scipy.interpolate.make_interp_spline(x_index, y, k=k)  # type: BSpline\n",
    "            y_new = spl(x_new)\n",
    "            df[col] = y_new\n",
    "        if return_type == 'df':\n",
    "            if datetime_index:\n",
    "                df.index = time_range\n",
    "            return df\n",
    "        if return_type == 'array':\n",
    "            return np.array(df.index), np.array(df.iloc[:, 0])\n",
    "        \n",
    "    elif isinstance(x, pd.Series):\n",
    "        var_name = x.name\n",
    "        y = x.copy()\n",
    "        x = x.index\n",
    "        \n",
    "        # n represents number of points to make between T.min and T.max\n",
    "        x_new = np.linspace(x.min(), x.max(), n) \n",
    "    \n",
    "        spl = scipy.interpolate.make_interp_spline(x, y, k=k)  # type: BSpline\n",
    "        y_new = spl(x_new)\n",
    "    \n",
    "        if return_type == 'dict':\n",
    "            if datetime_index:\n",
    "                ret_dict = {\n",
    "                    'x': time_range,\n",
    "                    'y': y_new\n",
    "                    }\n",
    "            else:\n",
    "                ret_dict = {\n",
    "                    'x': x_new,\n",
    "                    'y': y_new\n",
    "                    }\n",
    "            return ret_dict\n",
    "        elif return_type == 'array':\n",
    "            if datetime_index:\n",
    "                return time_range, y_new\n",
    "            else:\n",
    "                return x_new, y_new\n",
    "        elif return_type == 'df':\n",
    "            if datetime_index:\n",
    "                df = pd.DataFrame(data=y_new, index=time_range, columns=[var_name])\n",
    "            else:\n",
    "                df = pd.DataFrame(data=y_new, index=x_new, columns=[var_name])\n",
    "            return df\n",
    "    else:\n",
    "        y = x.copy()\n",
    "        x = arange(len(x))\n",
    "\n",
    "        # n represents number of points to make between T.min and T.max\n",
    "        x_new = np.linspace(x.min(), x.max(), n) \n",
    "    \n",
    "        spl = scipy.interpolate.make_interp_spline(x, y, k=k)  # type: BSpline\n",
    "        y_new = spl(x_new)\n",
    "        \n",
    "        if return_type == 'dict':\n",
    "            if datetime_index:\n",
    "                ret_dict = {\n",
    "                    'x': time_range,\n",
    "                    'y': y_new\n",
    "                    }\n",
    "            else:\n",
    "                ret_dict = {\n",
    "                    'x': x_new,\n",
    "                    'y': y_new\n",
    "                    }\n",
    "            return ret_dict\n",
    "        elif return_type == 'array':\n",
    "            if datetime_index:\n",
    "                return time_range, y_new\n",
    "            else:\n",
    "                return x_new, y_new\n",
    "        elif return_type == 'df':\n",
    "            if datetime_index:\n",
    "                df = pd.DataFrame(data=y_new, index=time_range, columns=['variable'])\n",
    "            else:\n",
    "                df = pd.DataFrame(data=y_new, index=x_new, columns=['variable'])\n",
    "            return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5f3677-3d20-453f-a524-efdee2836090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are NaNs in df\n",
    "\n",
    "def is_nan(df):\n",
    "    ret = df[df.isna().any(axis=1)]\n",
    "    shape = df[df.isna().any(axis=1)].shape\n",
    "    if shape[0] > 0:\n",
    "        return ret\n",
    "    else:\n",
    "        print(\"No NaN values in DataFrame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3573288-6dbd-4c0c-ae80-4f246e8b7a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_describe(data):\n",
    "    \n",
    "    df = data.copy()\n",
    "    # varibles types\n",
    "    dtypes = df.dtypes.rename('Type').to_frame()\n",
    "    # frequency\n",
    "    frequency = df.count().rename('Count').to_frame()\n",
    "    # unique values\n",
    "    unique = df.nunique().rename('Unique').to_frame()\n",
    "    # NaNs\n",
    "    nans = df.isnull().sum().rename('NaN').to_frame()\n",
    "    # NaNs fraction\n",
    "    nans_frac = df.isnull().mean().round(2)\n",
    "    nans_frac = nans_frac.rename('Percentages').to_frame()\n",
    "    # list with results\n",
    "    results_list = [dtypes, frequency, unique, nans, nans_frac]\n",
    "    # df with results\n",
    "    results = pd.concat(results_list, axis=1)\n",
    "    results['Percentages'] = (results['Percentages'] * 100).astype('int64')\n",
    "    results = results.sort_values(['NaN'], ascending=False)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e69162-437b-4836-9867-3f70ceeb3e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ci_bootstrap(\n",
    "        data, statistic=np.mean, n_bootstrap=1000,\n",
    "        confidence_level=0.95, random_state=42):\n",
    "    '''\n",
    "    Returns: dict(statistic, std, ci_min, ci_max, margin)\n",
    "    '''\n",
    "    data_ = (data,)\n",
    "    bootstrap = scipy.stats.bootstrap(\n",
    "        data=data_,\n",
    "        statistic=statistic,\n",
    "        n_resamples=n_bootstrap,\n",
    "        confidence_level=confidence_level,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    ci_min = bootstrap.confidence_interval[0]\n",
    "    ci_max = bootstrap.confidence_interval[1]\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        stat = data.apply(statistic)\n",
    "        stat = np.array(stat)\n",
    "        std = np.array(np.std(data, ddof=1))\n",
    "    else:\n",
    "        stat = statistic(data)\n",
    "        std = np.std(data, ddof=1)\n",
    "    margin = stat - ci_min\n",
    "\n",
    "    return_dct = {\n",
    "        'statistic': stat,\n",
    "        'std': std,\n",
    "        'ci_min': ci_min,\n",
    "        'ci_max': ci_max,\n",
    "        'margin': margin,\n",
    "    }\n",
    "    return return_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c7c8a1-48ea-4fbb-b723-2386a7ad10df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ci_t_distribution(\n",
    "        data=None, mean=None, std=None, n=None, confidence_level=0.95):\n",
    "\n",
    "    if data is not None:\n",
    "        arr = np.array(data)\n",
    "        n = len(arr)\n",
    "        mean = np.mean(arr)\n",
    "        se = scipy.stats.sem(arr)\n",
    "        \n",
    "    if mean and std and n is not None:\n",
    "        se = std / np.sqrt(n)\n",
    "\n",
    "    t = scipy.stats.t.ppf((1+confidence_level) / 2, n-1)\n",
    "    margin = t * se\n",
    "    ci_min = mean - margin\n",
    "    ci_max = mean + margin\n",
    "\n",
    "    return_dct = {\n",
    "        'mean': mean,\n",
    "        'ci_min': ci_min,\n",
    "        'ci_max': ci_max,\n",
    "        'margin': margin,\n",
    "        't': t\n",
    "    }\n",
    "    return return_dct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383bee6e-fc33-487d-be56-0294703199aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normality tests\n",
    "\n",
    "def test_normality(data, alpha=0.05):\n",
    "    \n",
    "    tests_names = []\n",
    "    pvalue = []\n",
    "    condition = []\n",
    "        \n",
    "    # Kolmogorov-Smirnov\n",
    "    ks = stats.kstest(data, 'norm')\n",
    "    pvalue_ks = ks.pvalue\n",
    "    tests_names.append('Kolmogorov-Smirnov')\n",
    "    pvalue.append(pvalue_ks)\n",
    "    if pvalue_ks < alpha:\n",
    "        condition.append('Not normal')\n",
    "    else:\n",
    "        condition.append('Normal')\n",
    "\n",
    "    # Anderson-Darling\n",
    "    and_dar = stats.anderson(data, dist='norm')\n",
    "    and_dar_sign = and_dar.critical_values[2]\n",
    "    and_dar_statistic = and_dar.statistic\n",
    "    tests_names.append('Anderson-Darling (s)')\n",
    "    pvalue.append(and_dar_statistic)\n",
    "    if and_dar_statistic > and_dar_sign:\n",
    "        condition.append('Not normal')\n",
    "    else:\n",
    "        condition.append('Normal')\n",
    "\n",
    "    # Shapiro-Wilk\n",
    "    pvalue_sw = stats.shapiro(data).pvalue\n",
    "    tests_names.append('Shapiro-Wilk')\n",
    "    pvalue.append(pvalue_sw)\n",
    "    if pvalue_sw < alpha:\n",
    "        condition.append('Not normal')\n",
    "    else:\n",
    "        condition.append('Normal')\n",
    "\n",
    "    # jarque-bera test\n",
    "    jb_name = [\"Jarque-Bera\", \"Chi^2\", \"Skew\", \"Kurtosis\"]\n",
    "    jb_statistic = sms.jarque_bera(data)\n",
    "    jb = dict(zip(jb_name, jb_statistic))\n",
    "    pvalue_jb = jb['Chi^2']\n",
    "    tests_names.append('Jarque-Bera')\n",
    "    pvalue.append(pvalue_jb)\n",
    "    if pvalue_jb < alpha:\n",
    "        condition.append('Not normal')\n",
    "    else:\n",
    "        condition.append('Normal')\n",
    "    \n",
    "    # D’Agostino and Pearson\n",
    "    dagp = stats.normaltest(data)\n",
    "    pvalue_dagp = dagp.pvalue\n",
    "    tests_names.append('D’Agostino-Pearson')\n",
    "    pvalue.append(pvalue_dagp)\n",
    "    if pvalue_dagp < alpha:\n",
    "        condition.append('Not normal')\n",
    "    else:\n",
    "        condition.append('Normal')\n",
    "\n",
    "    pvalue = [np.round(i, 4) for i in pvalue]\n",
    "    results_df = pd.DataFrame({\n",
    "        'Test': tests_names,\n",
    "        'P or Statistic (s)': pvalue,\n",
    "        'Condition': condition,\n",
    "    })\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531e9896-28f6-457d-9dbd-a0b1d6a449c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_display(\n",
    "        features, importance,\n",
    "        top=None, imp_min_level=None, only_features=True):\n",
    "\n",
    "    '''\n",
    "     \n",
    "    '''\n",
    "\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': features,\n",
    "        'Importance': importance\n",
    "    })\n",
    "    if imp_min_level is not None:\n",
    "        loc_row = feature_importance['Importance'] > imp_min_level\n",
    "        feature_importance = (feature_importance\n",
    "                              .loc[loc_row, :]\n",
    "                              .sort_values('Importance', ascending=False)\n",
    "                              .reset_index(drop=True))\n",
    "    if top is not None:\n",
    "        feature_importance = (feature_importance\n",
    "                             .sort_values('Importance', ascending=False)\n",
    "                             .reset_index(drop=True))\n",
    "        feature_importance = feature_importance.loc[0:top-1]\n",
    "\n",
    "    if only_features:\n",
    "        feature_importance = feature_importance['Feature']\n",
    "        \n",
    "    return feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d32e5c-c3b1-46a6-836b-26a86ef1bd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers_column_iqr(data, feature, scale=1.5):\n",
    "\n",
    "    '''\n",
    "    Add nominative (1/0) column '{feature}_is_out' in DataFrame, that indicates outliers for Feature\n",
    "    '''\n",
    "\n",
    "    df = data.copy()\n",
    "\n",
    "    q1 = df[feature].quantile(0.25)\n",
    "    q3 = df[feature].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_boundary = q1 - scale*iqr\n",
    "    upper_boundary = q3 + scale*iqr\n",
    "    condition = ((df[feature] < lower_boundary) |\n",
    "                 (df[feature] > upper_boundary))\n",
    "    df[feature+'_is_out'] = condition.astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8f4da8-115d-4638-ab0b-881d1a351a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_w_target(data, target):\n",
    "\n",
    "    '''\n",
    "    Create sorted DataFrame with correlations to Target \n",
    "    '''\n",
    "    \n",
    "    df = (data\n",
    "          .corr()[target]\n",
    "          .sort_values(ascending=False, key=abs)[1:]\n",
    "          .to_frame())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1ab501-a85a-45ee-b547-7b52f000f875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_columns_match(data):\n",
    "\n",
    "    '''\n",
    "    Check if all columns in DataFrame are equal and return no equal if not\n",
    "    '''\n",
    "\n",
    "    df = data.copy()\n",
    "    df['is_equal'] = df.eq(df.iloc[:, 0], axis=0).all(1).astype(int)\n",
    "    equal_sum = df['is_equal'].sum()\n",
    "\n",
    "    if equal_sum == len(df):\n",
    "        print('All values matched')\n",
    "        return None\n",
    "    else:\n",
    "        loc = df['is_equal'] == 0, df.columns != 'is_equal'\n",
    "        result = df.loc[loc].copy()\n",
    "        return result      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2bbff0-051e-4e1a-bdc3-fbbf82dba72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna_na(data, features_list):\n",
    "\n",
    "    '''\n",
    "    Fill all NaNs in DataFrame by 'NA'\n",
    "    '''\n",
    "\n",
    "    df = data.copy()\n",
    "    for feature in features_list:\n",
    "        df[feature] = df[feature].fillna('NA')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8d7a78-4e04-4843-a9c7-bd08e8391459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_by_first(data, return_type='df'):\n",
    "\n",
    "    '''\n",
    "    Normalize kind: \n",
    "        first_value == first_value\n",
    "        second_value = second_value / first_value\n",
    "        third_value = third_value / first_value\n",
    "    '''\n",
    "    \n",
    "    first_value = data[0]\n",
    "    \n",
    "    data_new = [(x/first_value) for x in data]\n",
    "\n",
    "    if return_type == 'df':\n",
    "        df = pd.DataFrame(data=data_new, index=data.index)\n",
    "        return df\n",
    "    if return_type == 'series':\n",
    "        series = pd.Series(data=data_new, index=data.index)\n",
    "        return series\n",
    "    elif return_type == 'array':\n",
    "        array = np.array(data_new)\n",
    "        return array\n",
    "    elif return_type == 'list':\n",
    "        lst = list(data_new)\n",
    "        return lst\n",
    "    else:\n",
    "        print(\"'return_type' must be 'df', 'series', 'array', 'list'\")\n",
    "    \n",
    "    return data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d2a7af-fcf4-41a0-ac7d-fbaf04bd47bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized(data, reshape=True, return_type='df'):\n",
    "\n",
    "    '''\n",
    "    MinMaxScaler 0/1 \n",
    "    '''\n",
    "    \n",
    "    if (isinstance(data, pd.Series) | \n",
    "        isinstance(data, pd.DataFrame)):\n",
    "        idxs = data.index.copy()\n",
    "    if reshape:\n",
    "        data = np.array(data).reshape(-1, 1)\n",
    "    data_new = MinMaxScaler().fit_transform(data)\n",
    "    if return_type == 'df':\n",
    "        data_new = pd.DataFrame(data=data_new, index=idxs)\n",
    "    elif return_type == 'array':\n",
    "        pass\n",
    "    else:\n",
    "        print(\"return_type must be 'df' or 'array'\")\n",
    "        return None\n",
    "        \n",
    "    return data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21ecd55-8dcf-4974-bf26-47a44816aa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skewness(df):\n",
    "\n",
    "    df = pd.DataFrame(df.skew(numeric_only=True),\n",
    "                      columns=['Skewness'],\n",
    "                      index=None)\n",
    "\n",
    "    df['Highly skewed'] = (abs(df['Skewness']) > 0.5)\n",
    "    df['abs'] = abs(df['Skewness'])\n",
    "\n",
    "    df = df.sort_values(by=['abs', 'Highly skewed'], ascending=False)\n",
    "    df = df.drop('abs', axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b841ad9-bea0-4e7d-9c4b-fbf38106f5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kurtosis(df):\n",
    "\n",
    "    df = pd.DataFrame(df.kurtosis(numeric_only=True),\n",
    "                      columns=['Kurtosis'],\n",
    "                      index=None)\n",
    "    df['Type'] = np.nan\n",
    "\n",
    "    df.loc[df['Kurtosis'] > 1, 'Type'] = 'Too Peaked'\n",
    "    df.loc[df['Kurtosis'] < -1, 'Type'] = 'Too Flat'\n",
    "    df.loc[(df['Kurtosis'] <= 1) & (df['Kurtosis'] >= -1), 'Type'] = 'Normal'\n",
    "    \n",
    "    df['abs'] = abs(df['Kurtosis'])\n",
    "    df = df.sort_values(by=['abs', 'Type'], ascending=False)\n",
    "    df = df.drop('abs', axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc657ab-e995-4630-af72-342906c3bbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acf(\n",
    "        acf_w_alphas=None, data=None, lags=40, partial=False, scatter=False, s=2,\n",
    "        transparency_lines=1, color_lines=None, exclude_first=True,\n",
    "        transparency_significant=0.15, color_significant=None, calculate=True, **kwargs):\n",
    "\n",
    "    if calculate:\n",
    "        acf_w_alphas = ts_acf_calculate(data, lags=lags, partial=partial, **kwargs) \n",
    "        \n",
    "    acf = acf_w_alphas[:, 0]\n",
    "    alphas = acf_w_alphas[:, 1:]\n",
    "    \n",
    "    lags = len(acf)\n",
    "    xticks = arange(lags)\n",
    "    color_palette = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "    color_significant = color_significant or color_palette[2]\n",
    "    color_lines = color_lines or color_palette[0]\n",
    "\n",
    "    if exclude_first:\n",
    "        acf[0] = 0\n",
    "        alphas[:1] = 0\n",
    "\n",
    "    if scatter:\n",
    "        plt.scatter(\n",
    "            x=xticks,\n",
    "            y=acf,\n",
    "            s=s\n",
    "        )\n",
    "    for i in arange(lags):\n",
    "        plt.plot(\n",
    "            [i, i],\n",
    "            [0, acf[i]],\n",
    "            color=color_lines,\n",
    "            alpha=transparency_lines\n",
    "        )\n",
    "    if exclude_first:\n",
    "        plt.fill_between(\n",
    "            arange(lags)[1:],\n",
    "            (alphas[:, 0] - acf)[1:],\n",
    "            (alphas[:, 1] - acf)[1:],\n",
    "            lw=0,\n",
    "            color=color_significant,\n",
    "            alpha=transparency_significant\n",
    "        )\n",
    "    else:\n",
    "        plt.fill_between(\n",
    "            arange(lags),\n",
    "            alphas[:, 0] - acf,\n",
    "            alphas[:, 1] - acf,\n",
    "            lw=0,\n",
    "            color=color_significant,\n",
    "            alpha=transparency_significant\n",
    "        )\n",
    "\n",
    "    \n",
    "    plt.plot([-1, lags], [0, 0])\n",
    "    plt.gca().spines[['bottom', 'left']].set_visible(False)\n",
    "    plt.grid(False)\n",
    "    plt.xlim(-2, lags+1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7be56e-4bcb-4aa4-a6d6-5fc455c77a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_acf_calculate(data, lags, alpha=0.05, partial=False):\n",
    "\n",
    "    if partial:\n",
    "        if isinstance(data, pd.Series) | isinstance(data, pd.DataFrame):\n",
    "            data = data.dropna()\n",
    "        acf_result = statsmodels.tsa.stattools.pacf(\n",
    "            data, nlags=lags, alpha=alpha, method='ywadjusted')\n",
    "    else:\n",
    "        acf_result = statsmodels.tsa.stattools.acf(\n",
    "            data, nlags=lags, alpha=alpha, missing='drop')\n",
    "\n",
    "    acf = acf_result[0][1:]\n",
    "    alphas = acf_result[1][1:]\n",
    "    result = np.hstack([acf.reshape(-1,1), alphas])\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18464e0c-294a-4961-9049-1bc6c04c8122",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_acf_last_significant_index(ci):\n",
    "    '''\n",
    "    Return index of first insignificant element in ACF or PACF\n",
    "\n",
    "    Attributes:\n",
    "        ci - confident intervals for ACF value (example, result[1] of statsmodels.tsa.stattools.acf)\n",
    "    '''\n",
    "    for i, j in enumerate(ci):\n",
    "        status = np.all(j > 0) if j[0] > 0 else np.all(j < 0)\n",
    "        if not status:\n",
    "            break\n",
    "    return i-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41001246-16a2-453d-8383-e5bbf258466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_arima_forecast(model, steps, data, ci=[80, 95]):\n",
    "\n",
    "    df = data.copy()\n",
    "    results = model.get_forecast(steps=steps)\n",
    "\n",
    "    final_df = pd.DataFrame(\n",
    "        index = pd.date_range(\n",
    "            df.index[0], results.predicted_mean.index[-1], freq=df.index.freq),\n",
    "        data=pd.concat([\n",
    "            df.iloc[:,0], results.predicted_mean], axis=0),\n",
    "        columns=['data'])\n",
    "\n",
    "    \n",
    "    final_df['forecast'] = np.where(\n",
    "        final_df.index.date < results.predicted_mean.index[0].date(), 0, 1)\n",
    "\n",
    "    for ci_value in ci:\n",
    "        alpha = (100 - ci_value) / 100\n",
    "        final_df[f'lower_ci{ci_value}'] = \\\n",
    "            results.conf_int(alpha=alpha).iloc[:, 0]\n",
    "        final_df[f'upper_ci{ci_value}'] = \\\n",
    "            results.conf_int(alpha=alpha).iloc[:, 1]\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26b2abc-90fc-46b7-8bbd-f1205fbe6bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_poisson_bootstrap(\n",
    "        data1, \n",
    "        data2,\n",
    "        n_bootstrap=10000,\n",
    "        ci=[2.5,97.5],\n",
    "        decimals = 3,\n",
    "        plot=True,\n",
    "        figsize=(7, 2),\n",
    "        colors=None,\n",
    "        execution_time=True,\n",
    "        results_dict=False,\n",
    "        means_plots=True,\n",
    "        rstyle=True,\n",
    "        rstyle_dataplot_kwargs={},\n",
    "        rstyle_meansplot_kwargs={},\n",
    "        simple_results=False):\n",
    "\n",
    "    '''\n",
    "    If plot == True and results_dict == True and means_plots == True\n",
    "    Returns: \n",
    "        - dict with means difference value and boundaries\n",
    "        - dict with Poisson bootstrap folds\n",
    "        - figure with means diffrenece plot with boundaries\n",
    "        - figure with data plots\n",
    "    '''\n",
    "\n",
    "    if simple_results:\n",
    "        plot = False\n",
    "        execution_time = False\n",
    "        results_dict = False\n",
    "        means_plots = False\n",
    "    \n",
    "    t_start = time.time()\n",
    "\n",
    "    if colors is None:\n",
    "        colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "    color0 = colors[0]\n",
    "    color1 = colors[1]\n",
    "    color_red = saturate_color('#CD4A3F', 0.9)\n",
    "    color_grey = '#5B5B5B'\n",
    "    color_grey_dark = '#505050'\n",
    "\n",
    "    if not isinstance(data1, np.ndarray):\n",
    "        data1 = np.array(data1)\n",
    "    if not isinstance(data2, np.ndarray):\n",
    "        data2 = np.array(data2)\n",
    "    \n",
    "    mean1 = np.mean(data1)\n",
    "    mean2 = np.mean(data2)\n",
    "\n",
    "    means_diff = mean1 - mean2\n",
    "\n",
    "    poisson_bootstraps1 = stats.poisson(1).rvs(\n",
    "        (n_bootstrap, len(data1))).astype(np.int64)\n",
    "\n",
    "    poisson_bootstraps2 = stats.poisson(1).rvs(\n",
    "        (n_bootstrap, len(data2))).astype(np.int64)\n",
    "\n",
    "    mean1_boot = (poisson_bootstraps1*data1).sum(axis=1) / len(data1)\n",
    "    mean2_boot = (poisson_bootstraps2*data2).sum(axis=1) / len(data2)\n",
    "    means_diff_boot = mean1_boot - mean2_boot\n",
    "    \n",
    "    lower_boundary, upper_boundary = np.percentile(means_diff_boot, ci)\n",
    "    \n",
    "    means_dict = {\n",
    "        'mean1': mean1_boot,\n",
    "        'mean2': mean2_boot,\n",
    "        'means_diff': means_diff_boot\n",
    "    }\n",
    "    \n",
    "    results = {\n",
    "        'Lower Boundary': lower_boundary, \n",
    "        'Means Difference': means_diff, \n",
    "        'Upper Boundary': upper_boundary\n",
    "    }\n",
    "\n",
    "    # if not simple_results:\n",
    "    #     if not plot:\n",
    "    #         print('\\n'+'         Poisson bootstrap summary')\n",
    "\n",
    "    if plot:\n",
    "\n",
    "        fig_data = plt.figure(figsize=figsize)\n",
    "\n",
    "        ax = sns.histplot(\n",
    "            means_diff_boot,\n",
    "            color=color_grey, alpha=0.4)\n",
    "\n",
    "        ylim = ax.get_ylim()[1]\n",
    "        \n",
    "        ax.vlines(\n",
    "            0, 0, ylim*0.1,\n",
    "            color=color_red, linewidth=2.5)\n",
    "        ax.vlines(\n",
    "            lower_boundary, 0, ylim*0.15,\n",
    "            color=color_grey_dark, linewidth=1.5)\n",
    "        ax.vlines(\n",
    "            upper_boundary, 0, ylim*0.15,\n",
    "            color=color_grey_dark, linewidth=1.5) \n",
    "\n",
    "        ax.set_ylabel('Count')\n",
    "\n",
    "        if rstyle:\n",
    "            axis_rstyle(**rstyle_dataplot_kwargs)\n",
    "\n",
    "        ax.legend(\n",
    "            **legend_inline(),\n",
    "            **legend_create_handles(\n",
    "                3, ['r', 'l', 'l'],\n",
    "                colors=[color_grey, color_red, color_grey_dark],\n",
    "                alphas=[0.4, 1, 1],\n",
    "                labels=['Means difference', 'Zero', 'Significance borders'],\n",
    "                linelength=1\n",
    "            ))\n",
    "\n",
    "        # ax.set_title('Poisson bootstrap summary', size=11, pad=27)\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "    # the boundaries, measured by 1 and 99 percentiles,\n",
    "    # are equvivalent of p-value probabiblities boundaries an 0.05 significant level;\n",
    "    # if difference in means is out of boundaries range, we reject null hypotesis - \n",
    "    # it means that the difference if statistical significant\n",
    "    if lower_boundary < 0 < upper_boundary:\n",
    "        significancy = False\n",
    "    else: \n",
    "        significancy = True\n",
    "    \n",
    "    # check with Kolmogorov–Smirnov test if distribution of p-values is normal\n",
    "    # (previously standardize means differences with stats.zscore)\n",
    "    pvalue_ks = stats.kstest(stats.zscore(means_diff_boot), stats.norm.cdf).pvalue\n",
    "    \n",
    "    # Kolmogorov–Smirnov test null hypotesis: distribution of simulation pvalues is normal\n",
    "    # if pvalue due Kolmogorov–Smirnov test <= 0.05, \n",
    "    # we reject null hypotesis that distribution of pvalues due simulation is normal;  \n",
    "    if pvalue_ks <= 0.05:\n",
    "        distribution = 'not '\n",
    "    else:\n",
    "        distribution = ''\n",
    "\n",
    "    if not simple_results:\n",
    "\n",
    "        mean1_rnd = f\"%.{decimals}f\" % mean1\n",
    "        mean2_rnd = f\"%.{decimals}f\" % mean2\n",
    "        lower_boundary_rnd = f\"%.{decimals}f\" % lower_boundary\n",
    "        means_diff_rnd = f\"%.{decimals}f\" % means_diff\n",
    "        upper_boundary_rnd = f\"%.{decimals}f\" % upper_boundary\n",
    "        pvalue_rnd = f\"%.{decimals}f\" % pvalue_ks\n",
    "        \n",
    "        ha1 = '===================================================================================='\n",
    "        start1 = '          '\n",
    "        space = '              '\n",
    "\n",
    "        delta1 = 27 - len(f'Lower Boundary:{lower_boundary_rnd}')\n",
    "        delta1 = delta1 * ' '\n",
    "        delta2 = 27 - len(f'Means Difference:{means_diff_rnd}')\n",
    "        delta2 = delta2 * ' '\n",
    "        delta3 = 27 - len(f'Upper Boundary:{upper_boundary_rnd}')\n",
    "        delta3 = delta3 * ' '\n",
    "\n",
    "        delta4 = 43 - len(f'Significantly difference:{significancy}')\n",
    "        delta4 = delta4 * ' '\n",
    "        delta5 = 43 - len(f\"Means Differences' distribution:{distribution}normal\")\n",
    "        delta5 = delta5 * ' '\n",
    "        delta6 = 43 - len(f'Kolmogorov–Smirnov test p-value:{pvalue_rnd}')\n",
    "        delta6 = delta6 * ' '\n",
    "\n",
    "        print(\n",
    "            '\\n'\n",
    "            f'{start1}'f'Significantly difference:{delta4}\\033[1m{significancy}\\033[0m' \\\n",
    "                + space + f'Lower Boundary:{delta1}{lower_boundary_rnd}' '\\n' \n",
    "            f'{start1}'f\"Means Differences' distribution:{delta5}{distribution}normal\" \\\n",
    "                + space + f'Means Difference:{delta2}{means_diff_rnd}' '\\n' \n",
    "            f'{start1}'+f'Kolmogorov–Smirnov test p-value:{delta6}{pvalue_rnd}' \\\n",
    "                + space+ f'Upper Boundary:{delta3}{upper_boundary_rnd}' '\\n' '\\n' \n",
    "            f'{start1}' + ha1 + '\\n' '\\n' \\\n",
    "            f'{start1}' + f'Sample 1 mean: {mean1_rnd}' '\\n'\n",
    "            f'{start1}' + f'Sample 2 mean: {mean2_rnd}')\n",
    "\n",
    "    if means_plots:\n",
    "        \n",
    "        fig_means = plt.figure(figsize=figsize)\n",
    "        \n",
    "        ax = sns.histplot(\n",
    "            mean1_boot,\n",
    "            color=color0, alpha=0.5)\n",
    "        \n",
    "        ax = sns.histplot(\n",
    "            mean2_boot, \n",
    "            color=color1, alpha=0.5)\n",
    "        \n",
    "        ax.set(xlabel=None)\n",
    "        ax.set_ylabel('Count', weight='bold')\n",
    "        ax.set_xlabel('Sample Means')\n",
    "        \n",
    "        ylim = ax.get_ylim()[1]\n",
    "        \n",
    "        ax.vlines(\n",
    "            np.mean(mean1_boot), 0, ylim,\n",
    "            color=saturate_color(color0, 1.25), linewidth=0.75, ls='--')\n",
    "        ax.vlines(\n",
    "            np.mean(mean2_boot), 0, ylim,\n",
    "            color=saturate_color(color1, 1.25), linewidth=0.75, ls='--')\n",
    "\n",
    "        if rstyle:\n",
    "            axis_rstyle(**rstyle_meansplot_kwargs)\n",
    "\n",
    "        ax.legend(\n",
    "            **legend_inline(),\n",
    "            **legend_create_handles(\n",
    "                2, 's',\n",
    "                colors=[color0, color1],\n",
    "                alphas=[0.5, 0.5],\n",
    "                labels=['Sample 1', 'Sample 2']))\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    if execution_time:\n",
    "        \n",
    "        execution_time = np.round(time.time() - t_start, 2)\n",
    "        execution_time_formated = \\\n",
    "                         str(dt.timedelta(seconds=np.round(time.time() - t_start)))\n",
    "        \n",
    "        print(f'{start1}'+'Execution time: {}'.format(execution_time_formated))\n",
    "        print(f'{start1}'+'Execution time (seconds): {}'.format(execution_time, '\\n'))\n",
    "\n",
    "    if results_dict:\n",
    "        return results, means_dict, fig_data, fig_means\n",
    "\n",
    "    if simple_results:\n",
    "        return significancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4482a4-a80b-4253-b375-04a976d84c33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85a1ff9-04f3-4e92-9a54-b22b4c50e086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c75f0e-9b17-404e-b7cb-b746dc4ed429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0253e652-3abc-4056-bc37-1644e43dc069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ac4cd9-a4e4-4961-a4e9-6d3a3ed351ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf32d641-d932-4f7f-9d7c-a29456a1be98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
